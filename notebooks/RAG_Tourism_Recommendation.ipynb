{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f7599f",
   "metadata": {},
   "source": [
    "## 1. Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb4786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /mnt/d/source/AI/SmartTraveling/.venv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m5 packages\u001b[0m \u001b[2min 890ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# Run this cell first if packages are not installed\n",
    "# !uv pip install langchain langchain-google-genai langchain-huggingface chromadb pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3debe9",
   "metadata": {},
   "source": [
    "## 2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65dedc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "import os\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dcb218",
   "metadata": {},
   "source": [
    "## 3. Configuration & API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a543645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Google API key here\n",
    "# Get your key from: https://makersuite.google.com/app/apikey\n",
    "GOOGLE_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Configuration\n",
    "CSV_PATH = '../data/processed/danh_sach_thong_tin_dia_danh_chi_tiet.csv'\n",
    "CHROMA_DB_PATH = '../data/vector_db/chroma_tourism'\n",
    "EMBEDDING_MODEL = 'sentence-transformers/multilingual-e5-large-instruct'\n",
    "TOP_K_RESULTS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dbdd30",
   "metadata": {},
   "source": [
    "## 4. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da39ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slugify(value: str) -> str:\n",
    "    \"\"\"\n",
    "    Convert Vietnamese text with diacritics into a URL-safe slug.\n",
    "    \n",
    "    Purpose: Create unique, safe identifiers for each location.\n",
    "    \n",
    "    Example:\n",
    "        \"Khu nh√† c√¥ng t·ª≠ B·∫°c Li√™u\" -> \"khu_nha_cong_tu_bac_lieu\"\n",
    "        \"Th√°c Khe V·∫±n\" -> \"thac_khe_van\"\n",
    "    \n",
    "    Args:\n",
    "        value: Vietnamese location name with diacritics\n",
    "    \n",
    "    Returns:\n",
    "        Lowercase slug with underscores (URL-safe)\n",
    "    \"\"\"\n",
    "    # Step 1: Convert Vietnamese 'ƒë' to 'd' (not handled by NFKD)\n",
    "    value = str(value).replace(\"ƒë\", \"d\").replace(\"ƒê\", \"D\")\n",
    "    \n",
    "    # Step 2: Remove Vietnamese diacritics using Unicode normalization\n",
    "    value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('utf-8')\n",
    "    \n",
    "    # Step 3: Remove special characters, keep only alphanumeric and spaces\n",
    "    value = re.sub(r'[^\\w\\s-]', '', value).strip().lower()\n",
    "    \n",
    "    # Step 4: Replace spaces and hyphens with underscores\n",
    "    value = re.sub(r'[\\s-]+', '_', value)\n",
    "    \n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6c49bf",
   "metadata": {},
   "source": [
    "## 5. Data Loading & Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f51eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_data(csv_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load tourism location CSV and prepare it for vectorization.\n",
    "    \n",
    "    Purpose: \n",
    "    - Load raw CSV data\n",
    "    - Generate loc_id for each location\n",
    "    - Filter out rows with missing critical fields\n",
    "    - Set loc_id as index for easy lookup\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to the CSV file\n",
    "    \n",
    "    Returns:\n",
    "        Processed DataFrame with loc_id as index\n",
    "    \"\"\"\n",
    "    print(\"üìÇ Loading CSV data...\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"   Loaded {len(df)} rows\")\n",
    "    \n",
    "    # Generate loc_id using slugify\n",
    "    print(\"üîë Generating loc_id for each location...\")\n",
    "    df['loc_id'] = df['TenDiaDanh'].apply(slugify)\n",
    "    \n",
    "    # Filter: Keep only rows with TenDiaDanh, DiaChi (NoiDung can be null)\n",
    "    print(\"üîç Filtering rows with missing critical data...\")\n",
    "    df_filtered = df.dropna(subset=['TenDiaDanh', 'DiaChi']).copy()\n",
    "    \n",
    "    # Fill NaN in NoiDung with empty string\n",
    "    df_filtered['NoiDung'] = df_filtered['NoiDung'].fillna('')\n",
    "    \n",
    "    print(f\"   Kept {len(df_filtered)} rows after filtering\")\n",
    "    \n",
    "    # Set loc_id as index for fast lookup\n",
    "    df_filtered = df_filtered.set_index('loc_id')\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31837d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading CSV data...\n",
      "   Loaded 958 rows\n",
      "üîë Generating loc_id for each location...\n",
      "üîç Filtering rows with missing critical data...\n",
      "   Kept 858 rows after filtering\n",
      "\n",
      "‚úÖ Data loaded successfully!\n",
      "   Total locations: 858\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TenDiaDanh</th>\n",
       "      <th>DiaChi</th>\n",
       "      <th>NoiDung</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loc_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>di_tich_lich_su_van_hoa_can_cu_dia_cach_mang_hai_chi_dinh_lang_da</th>\n",
       "      <td>Di t√≠ch l·ªãch s·ª≠ - vƒÉn h√≥a cƒÉn c·ª© ƒë·ªãa c√°ch m·∫°ng...</td>\n",
       "      <td>x√£ Thanh L√¢m, X√£ Thanh L√¢m, Huy·ªán Ba Ch·∫Ω, Qu·∫£n...</td>\n",
       "      <td>CƒÉn c·ª© ƒë·ªãa c√°ch m·∫°ng H·∫£i Chi l√† m·ªôt ƒë·ªãa danh l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cho_trung_tam_ba_che</th>\n",
       "      <td>Ch·ª£ Trung t√¢m Ba Ch·∫Ω</td>\n",
       "      <td>Th·ªã tr·∫•n Ba Ch·∫Ω, Th·ªã tr·∫•n Ba Ch·∫Ω, Huy·ªán Ba Ch·∫Ω...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>di_tich_lich_su_mieu_ong_mieu_ba</th>\n",
       "      <td>Di t√≠ch l·ªãch s·ª≠ Mi·∫øu √îng ‚Äì Mi·∫øu B√†</td>\n",
       "      <td>x√£ Nam S∆°n, X√£ Nam S∆°n, Huy·ªán Ba Ch·∫Ω, Qu·∫£ng Ninh</td>\n",
       "      <td>Mi·∫øu √îng v√† Mi·∫øu B√† t·ªça l·∫°c tr√™n n√∫i C√°i TƒÉn, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           TenDiaDanh  \\\n",
       "loc_id                                                                                                  \n",
       "di_tich_lich_su_van_hoa_can_cu_dia_cach_mang_ha...  Di t√≠ch l·ªãch s·ª≠ - vƒÉn h√≥a cƒÉn c·ª© ƒë·ªãa c√°ch m·∫°ng...   \n",
       "cho_trung_tam_ba_che                                                             Ch·ª£ Trung t√¢m Ba Ch·∫Ω   \n",
       "di_tich_lich_su_mieu_ong_mieu_ba                                   Di t√≠ch l·ªãch s·ª≠ Mi·∫øu √îng ‚Äì Mi·∫øu B√†   \n",
       "\n",
       "                                                                                               DiaChi  \\\n",
       "loc_id                                                                                                  \n",
       "di_tich_lich_su_van_hoa_can_cu_dia_cach_mang_ha...  x√£ Thanh L√¢m, X√£ Thanh L√¢m, Huy·ªán Ba Ch·∫Ω, Qu·∫£n...   \n",
       "cho_trung_tam_ba_che                                Th·ªã tr·∫•n Ba Ch·∫Ω, Th·ªã tr·∫•n Ba Ch·∫Ω, Huy·ªán Ba Ch·∫Ω...   \n",
       "di_tich_lich_su_mieu_ong_mieu_ba                     x√£ Nam S∆°n, X√£ Nam S∆°n, Huy·ªán Ba Ch·∫Ω, Qu·∫£ng Ninh   \n",
       "\n",
       "                                                                                              NoiDung  \n",
       "loc_id                                                                                                 \n",
       "di_tich_lich_su_van_hoa_can_cu_dia_cach_mang_ha...  CƒÉn c·ª© ƒë·ªãa c√°ch m·∫°ng H·∫£i Chi l√† m·ªôt ƒë·ªãa danh l...  \n",
       "cho_trung_tam_ba_che                                                                                   \n",
       "di_tich_lich_su_mieu_ong_mieu_ba                    Mi·∫øu √îng v√† Mi·∫øu B√† t·ªça l·∫°c tr√™n n√∫i C√°i TƒÉn, ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "tourism_df = load_and_process_data(CSV_PATH)\n",
    "print(f\"\\n‚úÖ Data loaded successfully!\")\n",
    "print(f\"   Total locations: {len(tourism_df)}\")\n",
    "print(f\"\\nSample data:\")\n",
    "tourism_df[['TenDiaDanh', 'DiaChi', 'NoiDung']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed5eacf",
   "metadata": {},
   "source": [
    "## 6. Document Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c778bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(df: pd.DataFrame) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Convert DataFrame rows into LangChain Document objects.\n",
    "    \n",
    "    Purpose:\n",
    "    - Create rich text content for embedding (TenDiaDanh + NoiDung + DiaChi)\n",
    "    - Store metadata (loc_id, original columns) for retrieval\n",
    "    - Each Document will be embedded and stored in ChromaDB\n",
    "    \n",
    "    Document Structure:\n",
    "    - page_content: Combined text for semantic search\n",
    "    - metadata: All original fields for context generation\n",
    "    \n",
    "    Args:\n",
    "        df: Processed DataFrame with loc_id as index\n",
    "    \n",
    "    Returns:\n",
    "        List of LangChain Document objects\n",
    "    \"\"\"\n",
    "    print(\"üìù Creating documents for vectorization...\")\n",
    "    documents = []\n",
    "    \n",
    "    for loc_id, row in df.iterrows():\n",
    "        # Build rich content: Title + Description + Location\n",
    "        # This combined text will be embedded for semantic search\n",
    "        content_parts = [\n",
    "            f\"T√™n ƒë·ªãa danh: {row['TenDiaDanh']}\",\n",
    "            f\"ƒê·ªãa ch·ªâ: {row['DiaChi']}\"\n",
    "        ]\n",
    "        \n",
    "        # Add description if available\n",
    "        if row['NoiDung'] and str(row['NoiDung']).strip():\n",
    "            content_parts.append(f\"M√¥ t·∫£: {row['NoiDung']}\")\n",
    "        \n",
    "        page_content = \"\\n\".join(content_parts)\n",
    "        \n",
    "        # Store all metadata for later use in recommendations\n",
    "        metadata = {\n",
    "            'loc_id': loc_id,\n",
    "            'TenDiaDanh': row['TenDiaDanh'],\n",
    "            'DiaChi': row['DiaChi'],\n",
    "            'NoiDung': row['NoiDung'] if row['NoiDung'] else '',\n",
    "            'ImageURL': row.get('ImageURL', ''),\n",
    "            'DichVu': row.get('DichVu', ''),\n",
    "            'ThongTinLienHe': row.get('ThongTinLienHe', ''),\n",
    "            'DanhGia': row.get('DanhGia (Google Map)', '')\n",
    "        }\n",
    "        \n",
    "        documents.append(Document(\n",
    "            page_content=page_content,\n",
    "            metadata=metadata\n",
    "        ))\n",
    "    \n",
    "    print(f\"   Created {len(documents)} documents\")\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bb7c749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Creating documents for vectorization...\n",
      "   Created 858 documents\n",
      "\n",
      "‚úÖ Documents created!\n",
      "\n",
      "Sample document:\n",
      "Content: T√™n ƒë·ªãa danh: Di t√≠ch l·ªãch s·ª≠ - vƒÉn h√≥a cƒÉn c·ª© ƒë·ªãa c√°ch m·∫°ng H·∫£i Chi (ƒê√¨nh L√†ng D·∫°)\n",
      "ƒê·ªãa ch·ªâ: x√£ Thanh L√¢m, X√£ Thanh L√¢m, Huy·ªán Ba Ch·∫Ω, Qu·∫£ng Ninh\n",
      "M√¥ t·∫£: CƒÉn c·ª© ƒë·ªãa c√°ch m·∫°ng H·∫£i Chi l√† m·ªôt ƒë·ªãa danh l·ªã...\n",
      "Metadata keys: ['loc_id', 'TenDiaDanh', 'DiaChi', 'NoiDung', 'ImageURL', 'DichVu', 'ThongTinLienHe', 'DanhGia']\n"
     ]
    }
   ],
   "source": [
    "# Create documents\n",
    "documents = create_documents(tourism_df)\n",
    "print(f\"\\n‚úÖ Documents created!\")\n",
    "print(f\"\\nSample document:\")\n",
    "print(f\"Content: {documents[0].page_content[:200]}...\")\n",
    "print(f\"Metadata keys: {list(documents[0].metadata.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea404481",
   "metadata": {},
   "source": [
    "## 7. Initialize Embeddings & Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33842f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vector_store(documents: List[Document], persist_directory: str) -> Chroma:\n",
    "    \"\"\"\n",
    "    Create embeddings and store in ChromaDB.\n",
    "    \n",
    "    Purpose:\n",
    "    - Initialize HuggingFace embeddings model (runs locally, no API needed)\n",
    "    - Convert all documents to vectors\n",
    "    - Store vectors in ChromaDB for fast similarity search\n",
    "    - Persist to disk for reuse\n",
    "    \n",
    "    Why ChromaDB:\n",
    "    - Persistent storage (no need to re-embed on restart)\n",
    "    - Fast similarity search\n",
    "    - Easy integration with LangChain\n",
    "    \n",
    "    Args:\n",
    "        documents: List of LangChain Documents\n",
    "        persist_directory: Path to store ChromaDB\n",
    "    \n",
    "    Returns:\n",
    "        Initialized Chroma vector store\n",
    "    \"\"\"\n",
    "    print(\"ü§ñ Initializing embedding model...\")\n",
    "    print(f\"   Model: {EMBEDDING_MODEL}\")\n",
    "    \n",
    "    # Initialize HuggingFace embeddings (free, runs locally)\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=EMBEDDING_MODEL,\n",
    "        model_kwargs={'device': 'cpu'},  # Use 'cuda' if GPU available\n",
    "        encode_kwargs={'normalize_embeddings': True}  # Normalize for cosine similarity\n",
    "    )\n",
    "    \n",
    "    print(\"üì¶ Creating ChromaDB vector store...\")\n",
    "    print(f\"   This may take a few minutes for {len(documents)} documents...\")\n",
    "    \n",
    "    # Create vector store (embeds all documents)\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings,\n",
    "        persist_directory=persist_directory,\n",
    "        collection_name=\"vietnam_tourism\"\n",
    "    )\n",
    "    \n",
    "    print(f\"   ‚úÖ Vector store created and persisted to: {persist_directory}\")\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0259775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Initializing embedding model...\n",
      "   Model: sentence-transformers/all-MiniLM-L6-v2\n",
      "üì¶ Creating ChromaDB vector store...\n",
      "   This may take a few minutes for 858 documents...\n",
      "   ‚úÖ Vector store created and persisted to: ../data/vector_db/chroma_tourism\n",
      "\n",
      "‚úÖ Vector store ready!\n"
     ]
    }
   ],
   "source": [
    "# Initialize vector store\n",
    "vector_store = initialize_vector_store(documents, CHROMA_DB_PATH)\n",
    "print(\"\\n‚úÖ Vector store ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279afe6b",
   "metadata": {},
   "source": [
    "## 8. Load Existing Vector Store (Optional)\n",
    "\n",
    "After the first run, you can load the existing vector store instead of re-creating it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82e07d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_existing_vector_store(persist_directory: str) -> Chroma:\n",
    "    \"\"\"\n",
    "    Load previously created vector store from disk.\n",
    "    \n",
    "    Purpose: Skip re-embedding on subsequent runs (saves time)\n",
    "    \n",
    "    Args:\n",
    "        persist_directory: Path where ChromaDB was persisted\n",
    "    \n",
    "    Returns:\n",
    "        Loaded Chroma vector store\n",
    "    \"\"\"\n",
    "    print(\"üìÇ Loading existing vector store...\")\n",
    "    \n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=EMBEDDING_MODEL,\n",
    "        model_kwargs={'device': 'cpu'},\n",
    "        encode_kwargs={'normalize_embeddings': True}\n",
    "    )\n",
    "    \n",
    "    vector_store = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=\"vietnam_tourism\"\n",
    "    )\n",
    "    \n",
    "    print(\"   ‚úÖ Vector store loaded\")\n",
    "    return vector_store\n",
    "\n",
    "# Uncomment to load existing store:\n",
    "# vector_store = load_existing_vector_store(CHROMA_DB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b661508f",
   "metadata": {},
   "source": [
    "## 12. Utility Functions for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae2d1866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(result: Dict):\n",
    "    \"\"\"\n",
    "    Print detailed analysis of recommendation results.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä DETAILED ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nüìç NEW PLACES ({len(result['new_places'])})\")\n",
    "    print(\"‚îÄ\" * 60)\n",
    "    for i, doc in enumerate(result['new_places'], 1):\n",
    "        meta = doc.metadata\n",
    "        print(f\"{i}. {meta['TenDiaDanh']}\")\n",
    "        print(f\"   ID: {meta['loc_id']}\")\n",
    "        print(f\"   ƒê·ªãa ch·ªâ: {meta['DiaChi']}\")\n",
    "        if meta.get('DanhGia'):\n",
    "            print(f\"   ƒê√°nh gi√°: {meta['DanhGia']}\")\n",
    "        print()\n",
    "    \n",
    "    if result['old_places']:\n",
    "        print(f\"\\nüîÑ VISITED PLACES ({len(result['old_places'])})\")\n",
    "        print(\"‚îÄ\" * 60)\n",
    "        for i, doc in enumerate(result['old_places'], 1):\n",
    "            meta = doc.metadata\n",
    "            print(f\"{i}. {meta['TenDiaDanh']} ({meta['loc_id']})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìù FINAL RESPONSE\")\n",
    "    print(\"‚ïê\" * 60)\n",
    "    print(result['final_response'])\n",
    "    print(\"‚ïê\" * 60)\n",
    "\n",
    "# Use it:\n",
    "# analyze_results(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b1ad97",
   "metadata": {},
   "source": [
    "## 13. Pipeline Summary\n",
    "\n",
    "### Complete Flow:\n",
    "\n",
    "```\n",
    "User Query: \"T√¥i mu·ªën t√¨m th√°c n∆∞·ªõc ƒë·∫πp\"\n",
    "           ‚Üì\n",
    "1. EMBEDDING: Convert query to vector using HuggingFace\n",
    "           ‚Üì\n",
    "2. VECTOR SEARCH: Find top-5 similar locations in ChromaDB\n",
    "           ‚Üì\n",
    "3. HISTORY FILTER:\n",
    "   - Check user_visited_ids\n",
    "   - Split into new_places & old_places\n",
    "   - Apply allow_revisit logic\n",
    "           ‚Üì\n",
    "4. CONTEXT BUILDING: Format location data for LLM\n",
    "           ‚Üì\n",
    "5. LLM GENERATION: Gemini creates friendly response\n",
    "           ‚Üì\n",
    "Output: Personalized recommendation text\n",
    "```\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "1. **Semantic Search**: Finds locations by meaning, not keywords\n",
    "2. **Visit History**: Remembers user preferences\n",
    "3. **Flexible Filtering**: Allow or prevent revisits\n",
    "4. **Rich Context**: Uses name + description + location\n",
    "5. **Natural Language**: Gemini generates friendly responses\n",
    "\n",
    "### Files Created:\n",
    "\n",
    "- **Vector DB**: `../data/vector_db/chroma_tourism/` (persistent)\n",
    "- **Documents**: In-memory LangChain Document objects\n",
    "- **Embeddings**: 384-dimensional vectors (all-MiniLM-L6-v2)\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Evaluation**: Test with different queries\n",
    "2. **Fine-tuning**: Adjust prompt template\n",
    "3. **Integration**: Connect to web/mobile app\n",
    "4. **Enhancement**: Add filters (price, rating, region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed83398",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0704ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    # google_api_key=GEMINI_API_KEY,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b90d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c98dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "tools = [retrieve_context]\n",
    "# If desired, specify custom instructions\n",
    "prompt = (\n",
    "    \"\"\"B·∫°n l√† m·ªôt h∆∞·ªõng d·∫´n vi√™n du l·ªãch Vi·ªát Nam th√¢n thi·ªán. Nhi·ªám v·ª• c·ªßa b·∫°n:\n",
    "\n",
    "    1. Lu√¥n ƒë·∫∑t c√¢u h·ªèi khai th√°c th√¥ng tin n·∫øu y√™u c·∫ßu c·ªßa ng∆∞·ªùi d√πng c√≤n m∆° h·ªì ho·∫∑c ch∆∞a ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ t∆∞ v·∫•n ch√≠nh x√°c.\n",
    "\n",
    "    2. Khi ng∆∞·ªùi d√πng y√™u c·∫ßu g·ª£i √Ω (v√≠ d·ª•: ƒë·ªãa ƒëi·ªÉm, qu√°n ƒÉn, l·ªãch tr√¨nh, th√¥ng tin l·ªãch s·ª≠ - vƒÉn h√≥a‚Ä¶), \n",
    "    b·∫°n ph·∫£i t·∫°o danh s√°ch c√°c c√¢u h·ªèi c·∫ßn thi·∫øt nh·∫±m l·∫•y ƒë·ªß d·ªØ li·ªáu ph·ª•c v·ª• truy xu·∫•t t·ª´ h·ªá th·ªëng RAG.\n",
    "\n",
    "    3. Khi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng y√™u c·∫ßu th√¥ng tin th·ª±c t·∫ø, d·ªØ li·ªáu c·ª• th·ªÉ, s·ª± th·∫≠t l·ªãch s·ª≠ ho·∫∑c chi ti·∫øt trong c∆° s·ªü d·ªØ li·ªáu, \n",
    "    b·∫°n **ƒë∆∞·ª£c ph√©p d√πng tool `retriever`**, nh∆∞ng ch·ªâ khi:\n",
    "        - C√¢u tr·∫£ l·ªùi c·∫ßn d·ªØ li·ªáu kh√¥ng c√≥ trong tr√≠ nh·ªõ m√¥ h√¨nh.\n",
    "        - Ng∆∞·ªùi d√πng y√™u c·∫ßu th√¥ng tin mang t√≠nh s·ª± ki·ªán, s·ªë li·ªáu, m√¥ t·∫£ ƒë·ªãa ƒëi·ªÉm th·ª±c t·∫ø.\n",
    "    N·∫øu kh√¥ng ch·∫Øc c√≥ d·ªØ li·ªáu ho·∫∑c ƒë·ªô tin c·∫≠y th·∫•p ‚Üí h√£y g·ªçi tool.\n",
    "\n",
    "    4. N·∫øu c√¢u h·ªèi n·∫±m ngo√†i chuy√™n m√¥n ho·∫∑c kh√¥ng c√≥ trong d·ªØ li·ªáu ‚Üí tr·∫£ l·ªùi: ‚ÄúT√¥i kh√¥ng bi·∫øt‚Äù.\n",
    "\n",
    "    5. Lu√¥n tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát th√¢n thi·ªán, t·ª± nhi√™n v√† r√µ r√†ng.\n",
    "\n",
    "    M·ª•c ti√™u cu·ªëi c√πng: ƒë∆∞a ra l·ªùi khuy√™n du l·ªãch ch√≠nh x√°c d·ª±a tr√™n d·ªØ li·ªáu, ƒë·ªìng th·ªùi ch·ªâ g·ªçi tool khi th·∫≠t s·ª± c·∫ßn thi·∫øt.\n",
    "    \"\"\"\n",
    ")\n",
    "agent = create_agent(model, tools, system_prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22315c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ TESTING AGENT WITH SAMPLE QUERIES\n",
      "\n",
      "============================================================\n",
      "\n",
      "üìù Query 1: T√¥i mu·ªën t√¨m nh·ªØng ƒë·ªãa ƒëi·ªÉm l·ªãch s·ª≠ c·ªï k√≠nh ·ªü mi·ªÅn B·∫Øc\n",
      "------------------------------------------------------------\n",
      "ü§ñ Response:\n",
      "Ch√†o b·∫°n, r·∫•t vui ƒë∆∞·ª£c h·ªó tr·ª£ b·∫°n. ƒê·ªÉ t√¥i c√≥ th·ªÉ g·ª£i √Ω nh·ªØng ƒë·ªãa ƒëi·ªÉm ph√π h·ª£p nh·∫•t, b·∫°n c√≥ th·ªÉ cho t√¥i bi·∫øt th√™m m·ªôt ch√∫t v·ªÅ s·ªü th√≠ch c·ªßa m√¨nh kh√¥ng? V√≠ d·ª•:\n",
      "\n",
      "*   B·∫°n th√≠ch nh·ªØng di t√≠ch g·∫Øn li·ªÅn v·ªõi tri·ªÅu ƒë·∫°i n√†o (v√≠ d·ª•: nh√† Tr·∫ßn, nh√† L√Ω, nh√† L√™...)?\n",
      "*   B·∫°n quan t√¢m ƒë·∫øn c√°c lo·∫°i h√¨nh di t√≠ch n√†o (v√≠ d·ª•: th√†nh qu√°ch, ƒë·ªÅn ch√πa, lƒÉng t·∫©m, l√†ng c·ªï...)?\n",
      "*   B·∫°n c√≥ d·ª± ƒë·ªãnh ƒëi v√†o d·ªãp n√†o kh√¥ng?\n",
      "*   B·∫°n th√≠ch kh√°m ph√° nh·ªØng ƒë·ªãa ƒëi·ªÉm mang ƒë·∫≠m d·∫•u ·∫•n l·ªãch s·ª≠ qu√¢n s·ª± hay vƒÉn h√≥a, t√≠n ng∆∞·ª°ng?\n",
      "\n",
      "C√†ng c√≥ nhi·ªÅu th√¥ng tin, t√¥i c√†ng d·ªÖ d√†ng t√¨m ra nh·ªØng vi√™n ng·ªçc l·ªãch s·ª≠ c·ªï k√≠nh d√†nh ri√™ng cho b·∫°n!\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Query 2: C√≥ th·ªÉ b·∫°n g·ª£i √Ω cho t√¥i m·ªôt l·ªãch tr√¨nh du l·ªãch 3 ng√†y?\n",
      "------------------------------------------------------------\n",
      "ü§ñ Response:\n",
      "Ch√†o b·∫°n, r·∫•t vui ƒë∆∞·ª£c gi√∫p b·∫°n l√™n k·∫ø ho·∫°ch cho chuy·∫øn ƒëi 3 ng√†y! ƒê·ªÉ m√¨nh c√≥ th·ªÉ g·ª£i √Ω m·ªôt l·ªãch tr√¨nh ph√π h·ª£p nh·∫•t, b·∫°n cho m√¨nh bi·∫øt th√™m m·ªôt ch√∫t th√¥ng tin nh√©:\n",
      "\n",
      "*   **B·∫°n d·ª± ƒë·ªãnh ƒëi du l·ªãch ·ªü ƒë√¢u?** (V√≠ d·ª•: H√† N·ªôi, ƒê√† N·∫µng, Ph√∫ Qu·ªëc, ƒê√† L·∫°t,...)\n",
      "*   **B·∫°n th√≠ch ki·ªÉu du l·ªãch n√†o?** (V√≠ d·ª•: ngh·ªâ d∆∞·ª°ng bi·ªÉn, kh√°m ph√° vƒÉn h√≥a - l·ªãch s·ª≠, trekking n√∫i, ·∫©m th·ª±c,...)\n",
      "*   **B·∫°n ƒëi c√πng ai?** (ƒêi m·ªôt m√¨nh, c·∫∑p ƒë√¥i, gia ƒë√¨nh c√≥ tr·∫ª nh·ªè, nh√≥m b·∫°n,...)\n",
      "*   **Ng√¢n s√°ch d·ª± ki·∫øn c·ªßa b·∫°n cho chuy·∫øn ƒëi n√†y l√† bao nhi√™u?** (Kho·∫£ng bao nhi√™u/ng∆∞·ªùi)\n",
      "*   **B·∫°n mu·ªën tr·∫£i nghi·ªám nh·ªØng g√¨ ƒë·∫∑c bi·ªát?** (V√≠ d·ª•: tham quan di t√≠ch l·ªãch s·ª≠, th∆∞·ªüng th·ª©c ƒë·∫∑c s·∫£n ƒë·ªãa ph∆∞∆°ng, tham gia l·ªÖ h·ªôi, ho·∫°t ƒë·ªông th·ªÉ thao d∆∞·ªõi n∆∞·ªõc,...)\n",
      "\n",
      "Sau khi c√≥ nh·ªØng th√¥ng tin n√†y, m√¨nh s·∫Ω d·ªÖ d√†ng x√¢y d·ª±ng m·ªôt l·ªãch tr√¨nh 3 ng√†y th·∫≠t h·∫•p d·∫´n d√†nh ri√™ng cho b·∫°n!\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìù Query 3: Th√°c n∆∞·ªõc n√†o ·ªü Vi·ªát Nam l√† ƒë·∫πp nh·∫•t?\n",
      "------------------------------------------------------------\n",
      "ü§ñ Response:\n",
      "Ch√†o b·∫°n, Vi·ªát Nam m√¨nh c√≥ r·∫•t nhi·ªÅu th√°c n∆∞·ªõc h√πng vƒ© v√† xinh ƒë·∫πp. ƒê·ªÉ m√¨nh c√≥ th·ªÉ g·ª£i √Ω th√°c n∆∞·ªõc ph√π h·ª£p nh·∫•t v·ªõi b·∫°n, b·∫°n c√≥ th·ªÉ cho m√¨nh bi·∫øt th√™m m·ªôt ch√∫t th√¥ng tin kh√¥ng?\n",
      "\n",
      "*   B·∫°n th√≠ch ki·ªÉu th√°c n∆∞·ªõc nh∆∞ th·∫ø n√†o? (V√≠ d·ª•: th√°c c√≥ nhi·ªÅu t·∫ßng, th√°c ch·∫£y xi·∫øt, th√°c c√≥ h·ªì n∆∞·ªõc trong xanh ƒë·ªÉ t·∫Øm, hay th√°c n·∫±m gi·ªØa r·ª´ng n√∫i hoang s∆°...)\n",
      "*   B·∫°n d·ª± ƒë·ªãnh ƒëi v√†o th·ªùi ƒëi·ªÉm n√†o trong nƒÉm?\n",
      "*   B·∫°n mu·ªën ƒë·∫øn th√°c n∆∞·ªõc ·ªü khu v·ª±c n√†o c·ªßa Vi·ªát Nam? (Mi·ªÅn B·∫Øc, mi·ªÅn Trung, hay mi·ªÅn Nam?)\n",
      "*   B·∫°n th√≠ch s·ª± y√™n tƒ©nh, thanh b√¨nh hay m·ªôt n∆°i ƒë√¥ng vui, nh·ªôn nh·ªãp?\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "‚úÖ AGENT TEST COMPLETED\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Test the agent with a sample conversation\n",
    "test_queries = [\n",
    "    \"T√¥i mu·ªën t√¨m nh·ªØng ƒë·ªãa ƒëi·ªÉm l·ªãch s·ª≠ c·ªï k√≠nh ·ªü mi·ªÅn B·∫Øc\",\n",
    "    \"C√≥ th·ªÉ b·∫°n g·ª£i √Ω cho t√¥i m·ªôt l·ªãch tr√¨nh du l·ªãch 3 ng√†y?\",\n",
    "    \"Th√°c n∆∞·ªõc n√†o ·ªü Vi·ªát Nam l√† ƒë·∫πp nh·∫•t?\"\n",
    "]\n",
    "\n",
    "print(\"ü§ñ TESTING AGENT WITH SAMPLE QUERIES\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\nüìù Query {i}: {query}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    try:\n",
    "        result = agent.invoke({\"messages\": [(\"user\", query)]})\n",
    "        \n",
    "        # Extract the last message from the agent\n",
    "        last_message = result[\"messages\"][-1]\n",
    "        response_text = last_message.content\n",
    "        \n",
    "        print(f\"ü§ñ Response:\\n{response_text}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "    \n",
    "    print(\"-\"*60)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ AGENT TEST COMPLETED\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1751300b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.3 environment at: /home/hienlong/projects/Tourism-Chatbot/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m34 packages\u001b[0m \u001b[2min 739ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)                                                   \n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/401.43 KiB          \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/401.43 KiB          \u001b[1A\n",
      "\u001b[2mpsycopg-pool        \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/39.06 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/401.43 KiB          \u001b[2A\n",
      "\u001b[2mpsycopg-pool        \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/39.06 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/401.43 KiB          \u001b[2A\n",
      "\u001b[2mpsycopg-pool        \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/39.06 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/401.43 KiB          \u001b[2A\n",
      "\u001b[2mpsycopg-pool        \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/39.06 KiB\n",
      "\u001b[2mlanggraph-sdk       \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/58.86 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/401.43 KiB          \u001b[3A\n",
      "\u001b[2mpsycopg-pool        \u001b[0m \u001b[32m-------------\u001b[30m\u001b[2m-----------------\u001b[0m\u001b[0m 16.00 KiB/39.06 KiB\n",
      "\u001b[2mlanggraph-sdk       \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/58.86 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/401.43 KiB          \u001b[3A\n",
      "\u001b[2mpsycopg-pool        \u001b[0m \u001b[32m-------------\u001b[30m\u001b[2m-----------------\u001b[0m\u001b[0m 16.00 KiB/39.06 KiB\n",
      "\u001b[2mlanggraph-sdk       \u001b[0m \u001b[32m---------\u001b[30m\u001b[2m---------------------\u001b[0m\u001b[0m 16.00 KiB/58.86 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/401.43 KiB          \u001b[3A\n",
      "\u001b[2mpsycopg-pool        \u001b[0m \u001b[32m-------------------------\u001b[30m\u001b[2m-----\u001b[0m\u001b[0m 32.00 KiB/39.06 KiB\n",
      "\u001b[2mlanggraph-sdk       \u001b[0m \u001b[32m---------\u001b[30m\u001b[2m---------------------\u001b[0m\u001b[0m 16.00 KiB/58.86 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/401.43 KiB          \u001b[3A\n",
      "\u001b[2mpsycopg-pool        \u001b[0m \u001b[32m-------------------------\u001b[30m\u001b[2m-----\u001b[0m\u001b[0m 32.00 KiB/39.06 KiB\n",
      "\u001b[2mlanggraph-sdk       \u001b[0m \u001b[32m-----------------\u001b[30m\u001b[2m-------------\u001b[0m\u001b[0m 32.00 KiB/58.86 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/401.43 KiB          \u001b[3A\n",
      "\u001b[2mpsycopg-pool        \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 39.06 KiB/39.06 KiB\n",
      "\u001b[2mlanggraph-sdk       \u001b[0m \u001b[32m-----------------\u001b[30m\u001b[2m-------------\u001b[0m\u001b[0m 32.00 KiB/58.86 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/401.43 KiB          \u001b[3A\n",
      "\u001b[2mpsycopg-pool        \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 39.06 KiB/39.06 KiB\n",
      "\u001b[2mlanggraph-sdk       \u001b[0m \u001b[32m-------------------------\u001b[30m\u001b[2m-----\u001b[0m\u001b[0m 48.00 KiB/58.86 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/401.43 KiB          \u001b[3A\n",
      "\u001b[2mpsycopg-pool        \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 39.06 KiB/39.06 KiB\n",
      "\u001b[2mlanggraph-sdk       \u001b[0m \u001b[32m-------------------------\u001b[30m\u001b[2m-----\u001b[0m\u001b[0m 48.00 KiB/58.86 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/401.43 KiB          \u001b[3A\n",
      "\u001b[2mpsycopg-pool        \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 39.06 KiB/39.06 KiB\n",
      "\u001b[2mlanggraph-sdk       \u001b[0m \u001b[32m-------------------------\u001b[30m\u001b[2m-----\u001b[0m\u001b[0m 48.00 KiB/58.86 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/401.43 KiB          \u001b[3A\n",
      "\u001b[2mpsycopg-pool        \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 39.06 KiB/39.06 KiB\n",
      "\u001b[2mlanggraph-sdk       \u001b[0m \u001b[32m-------------------------\u001b[30m\u001b[2m-----\u001b[0m\u001b[0m 48.00 KiB/58.86 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/401.43 KiB          \u001b[3A\n",
      "\u001b[2mpsycopg-pool        \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 39.06 KiB/39.06 KiB\n",
      "\u001b[2mlanggraph-sdk       \u001b[0m \u001b[32m-------------------------\u001b[30m\u001b[2m-----\u001b[0m\u001b[0m 48.00 KiB/58.86 KiB\n",
      "\u001b[2mlangsmith           \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/401.43 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/4.89 MiB            \u001b[4A\n",
      "\u001b[2mpsycopg-pool        \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 39.06 KiB/39.06 KiB\n",
      "\u001b[2mlanggraph-sdk       \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 58.86 KiB/58.86 KiB\n",
      "\u001b[2mlangsmith           \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/401.43 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/4.89 MiB            \u001b[4A\n",
      "\u001b[2mpsycopg-pool        \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 39.06 KiB/39.06 KiB\n",
      "\u001b[2mlanggraph-sdk       \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 58.86 KiB/58.86 KiB\n",
      "\u001b[2mlangsmith           \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/401.43 KiB\n",
      "\u001b[2K\u001b[4A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/4.89 MiB            \u001b[4A\n",
      "\u001b[2mlanggraph-sdk       \u001b[0m \u001b[32m------------------------------\u001b[30m\u001b[2m\u001b[0m\u001b[0m 58.86 KiB/58.86 KiB\n",
      "\u001b[2mlangsmith           \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/401.43 KiB\n",
      "\u001b[2K\u001b[3A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/4.89 MiB            \u001b[3A\n",
      "\u001b[2mlangsmith           \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/401.43 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m     0 B/4.89 MiB            \u001b[2A\n",
      "\u001b[2mlangsmith           \u001b[0m \u001b[32m\u001b[30m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/401.43 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m 16.00 KiB/4.89 MiB          \u001b[2A\n",
      "\u001b[2mlangsmith           \u001b[0m \u001b[32m-------------\u001b[30m\u001b[2m-----------------\u001b[0m\u001b[0m 172.65 KiB/401.43 KiB\n",
      "\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m 224.00 KiB/4.89 MiB         \u001b[2A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/6)-------------------\u001b[0m\u001b[0m 960.00 KiB/4.89 MiB         \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†π\u001b[0m \u001b[2mPreparing packages...\u001b[0m (5/6)-------------------\u001b[0m\u001b[0m 1008.00 KiB/4.89 MiB        \u001b[1A\n",
      "\u001b[2K\u001b[1A\u001b[37m‚†π\u001b[0m \u001b[2mPreparing packages...\u001b[0m (5/6)0m\u001b[2m-------------\u001b[0m\u001b[0m 2.72 MiB/4.89 MiB           \u001b[1A\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m6 packages\u001b[0m \u001b[2min 306ms\u001b[0m\u001b[0m                                                      \u001b[1A\n",
      "\u001b[2mUninstalled \u001b[1m3 packages\u001b[0m \u001b[2min 24ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m6 packages\u001b[0m \u001b[2min 13ms\u001b[0m\u001b[0m                                \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanggraph-checkpoint-postgres\u001b[0m\u001b[2m==3.0.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mlanggraph-sdk\u001b[0m\u001b[2m==0.2.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanggraph-sdk\u001b[0m\u001b[2m==0.2.12\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mlangsmith\u001b[0m\u001b[2m==0.4.49\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangsmith\u001b[0m\u001b[2m==0.4.50\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpsycopg-binary\u001b[0m\u001b[2m==3.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpsycopg-pool\u001b[0m\u001b[2m==3.3.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1murllib3\u001b[0m\u001b[2m==2.5.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install -U \"psycopg[binary,pool]\" langgraph langgraph-checkpoint-postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7def67e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg\n",
    "import uuid\n",
    "\n",
    "# Connect to your database\n",
    "conn = psycopg.connect(f\"postgresql://{os.getenv(\"PSQL_USERNAME\")}:{os.getenv(\"PSQL_PASSWORD\")}@{os.getenv(\"PSQL_HOST\")}:5432/{os.getenv(\"PSQL_DBNAME\")}\")\n",
    "conn.autocommit = True  # Important for simple scripts\n",
    "\n",
    "def ensure_mock_data():\n",
    "    \"\"\"Creates a mock user and thread if they don't exist.\"\"\"\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # 1. Generate IDs\n",
    "    mock_user_id = \"00000000-0000-0000-0000-000000000001\" # Fixed UUID for easy testing\n",
    "    mock_thread_id = \"00000000-0000-0000-0000-000000000002\"\n",
    "    \n",
    "    # 2. Insert Mock User (Ignore if exists)\n",
    "    try:\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO users (id, identifier, metadata)\n",
    "            VALUES (%s, 'test_user_01', '{}')\n",
    "            ON CONFLICT (id) DO NOTHING;\n",
    "        \"\"\", (mock_user_id,))\n",
    "    except Exception as e:\n",
    "        print(f\"User setup error: {e}\")\n",
    "\n",
    "    # 3. Insert Mock Thread (Ignore if exists)\n",
    "    try:\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO threads (id, name, \"userId\", \"userIdentifier\")\n",
    "            VALUES (%s, 'My Test Chat', %s, 'test_user_01')\n",
    "            ON CONFLICT (id) DO NOTHING;\n",
    "        \"\"\", (mock_thread_id, mock_user_id))\n",
    "    except Exception as e:\n",
    "        print(f\"Thread setup error: {e}\")\n",
    "        \n",
    "    print(f\"‚úÖ Setup Complete. Using Thread ID: {mock_thread_id}\")\n",
    "    return mock_thread_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9270892",
   "metadata": {},
   "source": [
    "## 14. Add Memory with PostgreSQL Checkpointer\n",
    "\n",
    "### Why Add a Checkpointer?\n",
    "\n",
    "A **checkpointer** enables your agent to:\n",
    "1. **Remember conversation history** across multiple turns\n",
    "2. **Persist state** to a database (PostgreSQL)\n",
    "3. **Resume conversations** even after restart\n",
    "4. **Track user context** (visited locations, preferences)\n",
    "\n",
    "### How It Works:\n",
    "\n",
    "```\n",
    "User Message ‚Üí Agent processes ‚Üí State saved to PostgreSQL\n",
    "    ‚Üì\n",
    "Next Message ‚Üí Agent loads previous state ‚Üí Continues conversation\n",
    "```\n",
    "\n",
    "### Setup Steps:\n",
    "\n",
    "1. Create PostgreSQL database\n",
    "2. Configure connection\n",
    "3. Add checkpointer to agent\n",
    "4. Test with multi-turn conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd31ef6",
   "metadata": {},
   "source": [
    "### Step 1: Database Configuration\n",
    "\n",
    "First, let's set up the database connection string and verify we can connect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b83f61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Database Configuration:\n",
      "   Host: localhost\n",
      "   Database: tourism_db\n",
      "   User: tourism\n",
      "\n",
      "‚úÖ Connected successfully!\n",
      "   PostgreSQL version: PostgreSQL 16.10 (Ubuntu 16.10-0ubuntu0.24.04.1) o...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg\n",
    "from psycopg_pool import ConnectionPool\n",
    "\n",
    "# Database configuration\n",
    "DB_CONFIG = {\n",
    "    \"host\": os.getenv(\"PSQL_HOST\", \"localhost\"),\n",
    "    \"port\": 5432,\n",
    "    \"dbname\": os.getenv(\"PSQL_DBNAME\", \"tourism_db\"),\n",
    "    \"user\": os.getenv(\"PSQL_USERNAME\", \"tourism\"),\n",
    "    \"password\": os.getenv(\"PSQL_PASSWORD\")\n",
    "}\n",
    "\n",
    "# Build connection string\n",
    "DB_URI = f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}\"\n",
    "\n",
    "print(\"üìä Database Configuration:\")\n",
    "print(f\"   Host: {DB_CONFIG['host']}\")\n",
    "print(f\"   Database: {DB_CONFIG['dbname']}\")\n",
    "print(f\"   User: {DB_CONFIG['user']}\")\n",
    "\n",
    "# Test connection\n",
    "try:\n",
    "    with psycopg.connect(DB_URI) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(\"SELECT version();\")\n",
    "            version = cur.fetchone()[0]\n",
    "            print(f\"\\n‚úÖ Connected successfully!\")\n",
    "            print(f\"   PostgreSQL version: {version[:50]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae424a1",
   "metadata": {},
   "source": [
    "### Step 2: Initialize PostgreSQL Checkpointer\n",
    "\n",
    "The `PostgresSaver` will automatically create the necessary tables (`checkpoints`, `checkpoint_writes`) in your database to store agent state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15e70ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Creating connection pool...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Initializing PostgreSQL checkpointer...\n",
      "üìã Setting up database schema...\n",
      "\n",
      "‚úÖ Checkpointer initialized!\n",
      "   Tables created: 'checkpoints', 'checkpoint_writes'\n"
     ]
    }
   ],
   "source": [
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "\n",
    "# Connection settings for LangGraph\n",
    "connection_kwargs = {\n",
    "    \"autocommit\": True,      # Auto-commit transactions\n",
    "    \"prepare_threshold\": 0   # Disable prepared statements (important for compatibility)\n",
    "}\n",
    "\n",
    "# Create connection pool\n",
    "print(\"üîß Creating connection pool...\")\n",
    "pool = ConnectionPool(\n",
    "    conninfo=DB_URI,\n",
    "    max_size=10,              # Maximum connections\n",
    "    kwargs=connection_kwargs\n",
    ")\n",
    "\n",
    "# Initialize checkpointer\n",
    "print(\"üíæ Initializing PostgreSQL checkpointer...\")\n",
    "checkpointer = PostgresSaver(pool)\n",
    "\n",
    "# Setup database schema (creates tables if they don't exist)\n",
    "print(\"üìã Setting up database schema...\")\n",
    "checkpointer.setup()\n",
    "\n",
    "print(\"\\n‚úÖ Checkpointer initialized!\")\n",
    "print(\"   Tables created: 'checkpoints', 'checkpoint_writes'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e61abc",
   "metadata": {},
   "source": [
    "### Step 3: Create Agent with Memory\n",
    "\n",
    "Now we'll recreate the agent using **LangGraph's ReAct pattern** with the checkpointer attached. This enables conversation memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4b781c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Creating agent with memory...\n",
      "‚úÖ Agent with memory created!\n",
      "\n",
      "üí° Key feature: Agent now remembers conversation history!\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Update the tool to include logging\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve tourism information to help answer a query about Vietnamese destinations.\"\"\"\n",
    "    print(f\"   üîß Tool called with query: '{query}'\")\n",
    "    \n",
    "    retrieved_docs = vector_store.similarity_search(query, k=3)\n",
    "    \n",
    "    print(f\"   üìä Retrieved {len(retrieved_docs)} documents\")\n",
    "    if retrieved_docs:\n",
    "        print(f\"   üìç Top result: {retrieved_docs[0].metadata.get('TenDiaDanh', 'N/A')}\")\n",
    "    \n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "# Define tools\n",
    "tools = [retrieve_context]\n",
    "\n",
    "# System prompt for the agent\n",
    "system_prompt = \"\"\"B·∫°n l√† m·ªôt h∆∞·ªõng d·∫´n vi√™n du l·ªãch Vi·ªát Nam th√¢n thi·ªán, gi√†u kinh nghi·ªám.\n",
    "\n",
    "Nhi·ªám v·ª• c·ªßa b·∫°n:\n",
    "1. ∆Øu ti√™n ƒë∆∞a ra th√¥ng tin h·ªØu √≠ch tr∆∞·ªõc, sau ƒë√≥ m·ªõi h·ªèi th√™m n·∫øu c·∫ßn.\n",
    "2. S·ª≠ d·ª•ng tool `retrieve_context` khi c·∫ßn th√¥ng tin th·ª±c t·∫ø v·ªÅ ƒë·ªãa danh Vi·ªát Nam.\n",
    "3. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát t·ª± nhi√™n, th√¢n thi·ªán v√† chi ti·∫øt.\n",
    "4. Ghi nh·ªõ ng·ªØ c·∫£nh cu·ªôc h·ªôi tho·∫°i tr∆∞·ªõc ƒë√≥.\n",
    "\n",
    "Khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ ƒë·ªãa ƒëi·ªÉm, h√£y:\n",
    "- G·ªçi tool ƒë·ªÉ l·∫•y th√¥ng tin ch√≠nh x√°c\n",
    "- Gi·ªõi thi·ªáu chi ti·∫øt v√† h·∫•p d·∫´n\n",
    "- G·ª£i √Ω l√Ω do n√™n gh√© thƒÉm\n",
    "\"\"\"\n",
    "\n",
    "# Create the agent with checkpointer (enables memory)\n",
    "print(\"ü§ñ Creating agent with memory...\")\n",
    "agent_with_memory = create_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    system_prompt=system_prompt,\n",
    "    checkpointer=checkpointer  # ‚Üê This enables memory!\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agent with memory created!\")\n",
    "print(\"\\nüí° Key feature: Agent now remembers conversation history!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5033c0",
   "metadata": {},
   "source": [
    "### Step 4: Test Multi-Turn Conversation\n",
    "\n",
    "Let's test the agent with a conversation that spans multiple turns. The agent should remember context from previous messages.\n",
    "\n",
    "**Important:** The `thread_id` is like a \"conversation ID\" - same thread_id = same conversation memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5918f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Conversation Thread ID: 1bb91edb-2276-4d16-8c61-74f8a71fcea9\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "def chat_with_agent(user_input: str, thread_id: str):\n",
    "    \"\"\"\n",
    "    Send a message to the agent and get response.\n",
    "    \n",
    "    Args:\n",
    "        user_input: User's message\n",
    "        thread_id: Conversation thread ID (same ID = same conversation)\n",
    "    \n",
    "    Returns:\n",
    "        Agent's response text\n",
    "    \"\"\"\n",
    "    # Configuration with thread_id for memory\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id  # This links to conversation history\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Prepare input\n",
    "    inputs = {\"messages\": [(\"user\", user_input)]}\n",
    "    \n",
    "    print(f\"\\nüë§ User: {user_input}\")\n",
    "    print(\"ü§ñ Agent thinking...\")\n",
    "    \n",
    "    response=\"\"\n",
    "    \n",
    "    # Invoke agent\n",
    "    for chunk in agent_with_memory.stream(inputs, config):\n",
    "        # # Extract response\n",
    "        # last_message = chunk[\"messages\"][-1]\n",
    "        # response = last_message.content\n",
    "        print(chunk)\n",
    "    \n",
    "    print(f\"ü§ñ Agent: {response}\\n\")\n",
    "    print(\"‚îÄ\" * 80)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Generate a unique thread ID for this conversation\n",
    "conversation_thread_id = '1bb91edb-2276-4d16-8c61-74f8a71fcea9'\n",
    "print(f\"üîë Conversation Thread ID: {conversation_thread_id}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2033951c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üë§ User: T√¥i mu·ªën t√¨m nh·ªØng th√°c n∆∞·ªõc ƒë·∫πp ·ªü Vi·ªát Nam\n",
      "ü§ñ Agent thinking...\n",
      "{'model': {'messages': [AIMessage(content='Vi·ªát Nam m√¨nh c√≥ r·∫•t nhi·ªÅu th√°c n∆∞·ªõc h√πng vƒ© v√† tuy·ªát ƒë·∫πp ƒë√≥ b·∫°n ∆°i! ƒê·ªÉ m√¨nh g·ª£i √Ω cho b·∫°n m·ªôt v√†i c√°i t√™n n·ªïi b·∫≠t nh√©:\\n\\n1.  **Th√°c B·∫£n Gi·ªëc (Cao B·∫±ng):** N·∫±m ·ªü bi√™n gi·ªõi Vi·ªát - Trung, ƒë√¢y l√† th√°c n∆∞·ªõc l·ªõn v√† ƒë·∫πp v√†o b·∫≠c nh·∫•t Vi·ªát Nam. B·∫°n s·∫Ω cho√°ng ng·ª£p tr∆∞·ªõc v·∫ª ƒë·∫πp c·ªßa d√≤ng th√°c ƒë·ªï xu·ªëng t·ª´ gh·ªÅnh ƒë√°, tung b·ªçt tr·∫Øng x√≥a, bao quanh l√† c·∫£nh n√∫i non tr√πng ƒëi·ªáp v√† nh·ªØng c√°nh ƒë·ªìng xanh m∆∞·ªõt. ƒê·∫∑c bi·ªát, v√†o m√πa l√∫a ch√≠n, khung c·∫£nh n∆°i ƒë√¢y c√†ng th√™m ph·∫ßn th∆° m·ªông.\\n\\n2.  **Th√°c Datanla (ƒê√† L·∫°t):** N·∫øu b·∫°n th√≠ch kh√°m ph√° v√† tr·∫£i nghi·ªám, Datanla l√† l·ª±a ch·ªçn tuy·ªát v·ªùi. Th√°c kh√¥ng ch·ªâ c√≥ v·∫ª ƒë·∫πp t·ª± nhi√™n m√† c√≤n c√≥ h·ªá th·ªëng m√°ng tr∆∞·ª£t xuy√™n r·ª´ng ƒë·ªôc ƒë√°o, mang l·∫°i c·∫£m gi√°c phi√™u l∆∞u th√∫ v·ªã.\\n\\n3.  **Th√°c Pongour (L√¢m ƒê·ªìng):** ƒê∆∞·ª£c m·ªánh danh l√† \"Nam thi√™n ƒë·ªá nh·∫•t th√°c\", Pongour s·ªü h·ªØu v·∫ª ƒë·∫πp hoang s∆°, k·ª≥ vƒ© v·ªõi h√†ng ng√†n d√≤ng ch·∫£y nh·ªè len l·ªèi qua c√°c b·∫≠c ƒë√° bazan t·∫°o n√™n m·ªôt b·ª©c tranh thi√™n nhi√™n s·ªëng ƒë·ªông.\\n\\n4.  **Th√°c Su·ªëi B·∫°c (Sa Pa):** N·∫±m gi·ªØa thung l≈©ng, th√°c Su·ªëi B·∫°c mang v·∫ª ƒë·∫πp trong l√†nh, m√°t r∆∞·ª£i v·ªõi d√≤ng n∆∞·ªõc tr·∫Øng nh∆∞ b·∫°c ƒë·ªï xu·ªëng t·ª´ tr√™n cao. Xung quanh th√°c l√† c·∫£nh s·∫Øc n√∫i r·ª´ng Sa Pa h√πng vƒ©.\\n\\nB·∫°n th√≠ch ki·ªÉu th√°c n∆∞·ªõc nh∆∞ th·∫ø n√†o, hay c√≥ v√πng mi·ªÅn n√†o b·∫°n ƒë·∫∑c bi·ªát quan t√¢m kh√¥ng? M√¨nh c√≥ th·ªÉ t√¨m hi·ªÉu th√™m th√¥ng tin chi ti·∫øt h∆°n cho b·∫°n ƒë√≥!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--45ee9f9e-fd53-4be3-96d7-221eb46c6496-0', usage_metadata={'input_tokens': 2534, 'output_tokens': 371, 'total_tokens': 2905, 'input_token_details': {'cache_read': 0}})]}}\n",
      "ü§ñ Agent: \n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
     ]
    }
   ],
   "source": [
    "# Test 1: First message - ask about waterfalls\n",
    "response1 = chat_with_agent(\n",
    "    \"T√¥i mu·ªën t√¨m nh·ªØng th√°c n∆∞·ªõc ƒë·∫πp ·ªü Vi·ªát Nam\",\n",
    "    thread_id=conversation_thread_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b11b8081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üë§ User: C√°i n√†o g·∫ßn ƒê√† N·∫µng nh·∫•t?\n",
      "ü§ñ Agent thinking...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Agent: D·∫°, trong c√°c th√°c n∆∞·ªõc m√¨nh v·ª´a k·ªÉ th√¨ **Th√°c Datanla** l√† g·∫ßn ƒê√† N·∫µng nh·∫•t. Th√°c n√†y n·∫±m ·ªü ƒê√† L·∫°t, L√¢m ƒê·ªìng. T·ª´ ƒê√† N·∫µng, b·∫°n c√≥ th·ªÉ ƒëi m√°y bay ho·∫∑c xe kh√°ch ƒë·∫øn ƒê√† L·∫°t, sau ƒë√≥ di chuy·ªÉn th√™m m·ªôt ƒëo·∫°n ng·∫Øn n·ªØa l√† t·ªõi th√°c Datanla.\n",
      "\n",
      "Ngo√†i ra, n·∫øu b·∫°n mu·ªën t√¨m nh·ªØng th√°c n∆∞·ªõc ƒë·∫πp n·∫±m trong khu v·ª±c mi·ªÅn Trung v√† kh√¥ng qu√° xa ƒê√† N·∫µng, m√¨nh c√≥ th·ªÉ t√¨m hi·ªÉu th√™m v√† gi·ªõi thi·ªáu cho b·∫°n. B·∫°n c√≥ mu·ªën m√¨nh t√¨m hi·ªÉu kh√¥ng?\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
     ]
    }
   ],
   "source": [
    "# Test 2: Follow-up question (should remember we're talking about waterfalls)\n",
    "response2 = chat_with_agent(\n",
    "    \"C√°i n√†o g·∫ßn ƒê√† N·∫µng nh·∫•t?\",\n",
    "    thread_id=conversation_thread_id  # Same thread = remembers context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca91d594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üë§ User: T√¥i ƒë√£ t·ª´ng ƒë·∫øn n∆°i ƒë·∫ßu ti√™n b·∫°n g·ª£i √Ω r·ªìi, n∆°i n√†o kh√°c?\n",
      "ü§ñ Agent thinking...\n",
      "ü§ñ Agent: D·∫°, b·∫°n ƒë√£ gh√© thƒÉm Th√°c B·∫£n Gi·ªëc r·ªìi ·∫°. V·∫≠y th√¨ m√¨nh s·∫Ω t·∫≠p trung v√†o nh·ªØng l·ª±a ch·ªçn kh√°c nh√©.\n",
      "\n",
      "B·∫°n c√≤n nh·ªõ m√¨nh ƒë√£ g·ª£i √Ω Th√°c Datanla v√† Th√°c Pongour ·ªü L√¢m ƒê·ªìng, c√πng Th√°c Su·ªëi B·∫°c ·ªü Sa Pa.\n",
      "\n",
      "N·∫øu b·∫°n mu·ªën t√¨m m·ªôt ƒë·ªãa ƒëi·ªÉm kh√°c ngo√†i nh·ªØng n∆°i n√†y, b·∫°n c√≥ mu·ªën m√¨nh t√¨m hi·ªÉu v·ªÅ c√°c th√°c n∆∞·ªõc ·ªü khu v·ª±c mi·ªÅn Trung ho·∫∑c c√°c v√πng kh√°c kh√¥ng? Ho·∫∑c b·∫°n c√≥ ti√™u ch√≠ n√†o kh√°c cho chuy·∫øn ƒëi c·ªßa m√¨nh kh√¥ng, v√≠ d·ª• nh∆∞:\n",
      "\n",
      "*   B·∫°n th√≠ch s·ª± hoang s∆°, h√πng vƒ© hay v·∫ª ƒë·∫πp th∆° m·ªông, tr·ªØ t√¨nh?\n",
      "*   B·∫°n mu·ªën k·∫øt h·ª£p tham quan th√°c n∆∞·ªõc v·ªõi c√°c ho·∫°t ƒë·ªông kh√°c nh∆∞ trekking, c·∫Øm tr·∫°i?\n",
      "*   B·∫°n c√≥ d·ª± ƒë·ªãnh ƒëi v√†o m√πa n√†o trong nƒÉm kh√¥ng?\n",
      "\n",
      "Cho m√¨nh bi·∫øt th√™m m·ªôt ch√∫t ƒë·ªÉ m√¨nh c√≥ th·ªÉ g·ª£i √Ω ch√≠nh x√°c h∆°n nh√©!\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n"
     ]
    }
   ],
   "source": [
    "# Test 3: Another follow-up (testing long-term memory)\n",
    "response3 = chat_with_agent(\n",
    "    \"T√¥i ƒë√£ t·ª´ng ƒë·∫øn n∆°i ƒë·∫ßu ti√™n b·∫°n g·ª£i √Ω r·ªìi, n∆°i n√†o kh√°c?\",\n",
    "    thread_id=conversation_thread_id  # Still same conversation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1d495",
   "metadata": {},
   "source": [
    "### Step 5: Verify Memory Persistence\n",
    "\n",
    "Let's verify that the conversation is actually saved in PostgreSQL and can be retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89ca039c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Database Status:\n",
      "   Total checkpoints: 33\n",
      "\n",
      "üìã Recent checkpoints:\n",
      "   - Thread: 00000000-0000-0000-0... | Checkpoint: 1f0d04c8-d9fb-652c-b...\n",
      "   - Thread: 00000000-0000-0000-0... | Checkpoint: 1f0d04c8-da01-607f-8...\n",
      "   - Thread: 00000000-0000-0000-0... | Checkpoint: 1f0d04c9-0d5f-6cf7-8...\n",
      "   - Thread: 00000000-0000-0000-0... | Checkpoint: 1f0d04c9-4ea4-6ce9-8...\n",
      "   - Thread: 00000000-0000-0000-0... | Checkpoint: 1f0d04c9-4ea9-60bb-8...\n",
      "\n",
      "‚úÖ Our conversation has 15 checkpoints saved!\n"
     ]
    }
   ],
   "source": [
    "# Check what's stored in the database\n",
    "with psycopg.connect(DB_URI) as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        # Count checkpoints\n",
    "        cur.execute(\"SELECT COUNT(*) FROM checkpoints;\")\n",
    "        checkpoint_count = cur.fetchone()[0]\n",
    "        \n",
    "        # Get recent checkpoints\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT thread_id, checkpoint_id \n",
    "            FROM checkpoints  \n",
    "            LIMIT 5;\n",
    "        \"\"\")\n",
    "        recent_checkpoints = cur.fetchall()\n",
    "        \n",
    "        print(\"üìä Database Status:\")\n",
    "        print(f\"   Total checkpoints: {checkpoint_count}\")\n",
    "        print(f\"\\nüìã Recent checkpoints:\")\n",
    "        for thread_id, checkpoint_id in recent_checkpoints:\n",
    "            print(f\"   - Thread: {thread_id[:20]}... | Checkpoint: {checkpoint_id[:20]}...\")\n",
    "        \n",
    "        # Check if our conversation is saved\n",
    "        cur.execute(\"\"\"\n",
    "            SELECT COUNT(*) FROM checkpoints \n",
    "            WHERE thread_id = %s;\n",
    "        \"\"\", (conversation_thread_id,))\n",
    "        our_checkpoints = cur.fetchone()[0]\n",
    "        \n",
    "        print(f\"\\n‚úÖ Our conversation has {our_checkpoints} checkpoints saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8eb3eb0",
   "metadata": {},
   "source": [
    "### Step 6: Test with New Thread (No Memory)\n",
    "\n",
    "Let's create a new conversation with a different thread_id. The agent should NOT remember the previous conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca60a9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë New Conversation Thread ID: 554e6357-25fe-4dd8-938e-6e5ecd7b6108\n",
      "================================================================================\n",
      "\n",
      "üë§ User: C√°i n√†o g·∫ßn ƒê√† N·∫µng nh·∫•t?\n",
      "ü§ñ Agent thinking...\n",
      "ü§ñ Agent: Ch√†o b·∫°n, ƒë·ªÉ bi·∫øt ƒë·ªãa ƒëi·ªÉm n√†o g·∫ßn ƒê√† N·∫µng nh·∫•t, b·∫°n c√≥ th·ªÉ cho m√¨nh bi·∫øt b·∫°n ƒëang quan t√¢m ƒë·∫øn lo·∫°i ƒë·ªãa ƒëi·ªÉm n√†o kh√¥ng? V√≠ d·ª• nh∆∞ b√£i bi·ªÉn, danh lam th·∫Øng c·∫£nh, khu vui ch∆°i gi·∫£i tr√≠ hay m·ªôt ƒë·ªãa ƒëi·ªÉm c·ª• th·ªÉ n√†o ƒë√≥?\n",
      "\n",
      "N·∫øu b·∫°n th√≠ch kh√°m ph√° thi√™n nhi√™n v√† l·ªãch s·ª≠, **Ph·ªë c·ªï H·ªôi An** l√† m·ªôt l·ª±a ch·ªçn tuy·ªát v·ªùi. H·ªôi An c√°ch ƒê√† N·∫µng kho·∫£ng 30km, b·∫°n c√≥ th·ªÉ d·ªÖ d√†ng di chuy·ªÉn b·∫±ng xe m√°y ho·∫∑c √¥ t√¥ ch·ªâ trong v√≤ng 30-45 ph√∫t. N∆°i ƒë√¢y n·ªïi ti·∫øng v·ªõi nh·ªØng ng√¥i nh√† c·ªï k√≠nh, nh·ªØng con ƒë∆∞·ªùng ƒë√®n l·ªìng lung linh v·ªÅ ƒë√™m v√† ·∫©m th·ª±c ƒë·∫∑c s·∫Øc.\n",
      "\n",
      "Ngo√†i ra, n·∫øu b·∫°n mu·ªën t√¨m ki·∫øm m·ªôt b√£i bi·ªÉn hoang s∆° v√† y√™n tƒ©nh h∆°n, **Bi·ªÉn LƒÉng C√¥** c≈©ng l√† m·ªôt ƒëi·ªÉm ƒë·∫øn l√Ω t∆∞·ªüng. LƒÉng C√¥ c√°ch ƒê√† N·∫µng kho·∫£ng 70km v·ªÅ ph√≠a B·∫Øc, n·ªïi ti·∫øng v·ªõi v·∫ª ƒë·∫πp t·ª± nhi√™n h√πng vƒ©, b√£i c√°t tr·∫Øng m·ªãn v√† l√†n n∆∞·ªõc trong xanh.\n",
      "\n",
      "B·∫°n c√≥ th·ªÉ cho m√¨nh bi·∫øt th√™m s·ªü th√≠ch c·ªßa m√¨nh ƒë·ªÉ m√¨nh c√≥ th·ªÉ g·ª£i √Ω ch√≠nh x√°c h∆°n nh√©!\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üí° Notice: Agent doesn't know what 'C√°i n√†o' refers to because this is a new conversation!\n"
     ]
    }
   ],
   "source": [
    "# Start a completely new conversation\n",
    "new_thread_id = str(uuid.uuid4())\n",
    "print(f\"üîë New Conversation Thread ID: {new_thread_id}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Ask the same follow-up question from before\n",
    "# This should fail or ask for clarification since there's no context\n",
    "response_new = chat_with_agent(\n",
    "    \"C√°i n√†o g·∫ßn ƒê√† N·∫µng nh·∫•t?\",  # Same question as before\n",
    "    thread_id=new_thread_id  # Different thread = no memory!\n",
    ")\n",
    "\n",
    "print(\"\\nüí° Notice: Agent doesn't know what 'C√°i n√†o' refers to because this is a new conversation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3abef42",
   "metadata": {},
   "source": [
    "### Step 7: Resume Previous Conversation\n",
    "\n",
    "Let's go back to the first conversation using the original thread_id. The agent should remember everything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e9eabf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Resuming Original Thread: 1bb91edb-2276-4d16-8c61-74f8a71fcea9\n",
      "================================================================================\n",
      "\n",
      "üë§ User: C·∫£m ∆°n! Cho t√¥i bi·∫øt th√™m v·ªÅ ƒë·ªãa ƒëi·ªÉm ƒë·∫ßu ti√™n nh√©\n",
      "ü§ñ Agent thinking...\n",
      "ü§ñ Agent: Tuy·ªát v·ªùi! **Th√°c B·∫£n Gi·ªëc** ·ªü t·ªânh Cao B·∫±ng l√† m·ªôt l·ª±a ch·ªçn kh√¥ng th·ªÉ b·ªè qua khi n√≥i ƒë·∫øn c√°c th√°c n∆∞·ªõc ƒë·∫πp ·ªü Vi·ªát Nam.\n",
      "\n",
      "ƒê√¢y l√† m·ªôt k·ª≥ quan thi√™n nhi√™n h√πng vƒ©, n·∫±m ngay tr√™n bi√™n gi·ªõi gi·ªØa Vi·ªát Nam v√† Trung Qu·ªëc. ƒêi·ªÅu l√†m n√™n s·ª± ƒë·∫∑c bi·ªát c·ªßa B·∫£n Gi·ªëc ch√≠nh l√† s·ª± r·ªông l·ªõn v√† v·∫ª ƒë·∫πp ·∫•n t∆∞·ª£ng c·ªßa n√≥:\n",
      "\n",
      "*   **Quy m√¥ ·∫•n t∆∞·ª£ng:** Th√°c B·∫£n Gi·ªëc l√† th√°c n∆∞·ªõc l·ªõn th·ª© t∆∞ th·∫ø gi·ªõi n·∫±m tr√™n m·ªôt ƒë∆∞·ªùng bi√™n gi·ªõi qu·ªëc gia. D√≤ng n∆∞·ªõc t·ª´ s√¥ng Qu√¢y S∆°n ƒë·ªï xu·ªëng qua nhi·ªÅu b·∫≠c ƒë√° v√¥i, t·∫°o th√†nh m·ªôt m√†n n∆∞·ªõc tr·∫Øng x√≥a, b·ªçt tung tr·∫Øng x√≥a, √¢m thanh vang d·ªôi c·∫£ m·ªôt v√πng.\n",
      "*   **C·∫£nh quan th∆° m·ªông:** Bao quanh th√°c l√† khung c·∫£nh n√∫i non tr√πng ƒëi·ªáp, nh·ªØng c√°nh ƒë·ªìng l√∫a xanh m∆∞·ªõt (ƒë·∫∑c bi·ªát ƒë·∫πp v√†o m√πa l√∫a ch√≠n), v√† nh·ªØng b·∫£n l√†ng d√¢n t·ªôc m·ªôc m·∫°c. B·∫°n c√≥ th·ªÉ ƒëi thuy·ªÅn ƒë·∫øn g·∫ßn ch√¢n th√°c ƒë·ªÉ c·∫£m nh·∫≠n r√µ h∆°n s·ª± h√πng vƒ© v√† h∆°i n∆∞·ªõc m√°t l·∫°nh.\n",
      "*   **Ho·∫°t ƒë·ªông tr·∫£i nghi·ªám:** Ngo√†i vi·ªác chi√™m ng∆∞·ª°ng v·∫ª ƒë·∫πp c·ªßa th√°c, b·∫°n c√≥ th·ªÉ ƒëi thuy·ªÅn tham quan, kh√°m ph√° c√°c hang ƒë·ªông g·∫ßn ƒë√≥ nh∆∞ ƒë·ªông Ng∆∞·ªùm Ngao, ho·∫∑c t√¨m hi·ªÉu vƒÉn h√≥a c·ªßa ƒë·ªìng b√†o d√¢n t·ªôc T√†y, N√πng sinh s·ªëng quanh khu v·ª±c.\n",
      "\n",
      "**L√Ω do b·∫°n n√™n gh√© thƒÉm Th√°c B·∫£n Gi·ªëc:**\n",
      "\n",
      "*   ƒê·ªÉ chi√™m ng∆∞·ª°ng m·ªôt trong nh·ªØng k·ª≥ quan thi√™n nhi√™n ƒë·∫πp nh·∫•t Vi·ªát Nam.\n",
      "*   ƒê·ªÉ c√≥ nh·ªØng b·ª©c ·∫£nh check-in ƒë·ªôc ƒë√°o t·∫°i v√πng bi√™n c∆∞∆°ng.\n",
      "*   ƒê·ªÉ tr·∫£i nghi·ªám kh√¥ng kh√≠ trong l√†nh, y√™n b√¨nh v√† kh√°m ph√° vƒÉn h√≥a ƒë·ªãa ph∆∞∆°ng.\n",
      "\n",
      "B·∫°n c√≥ mu·ªën bi·∫øt th√™m v·ªÅ c√°ch di chuy·ªÉn ƒë·∫øn Th√°c B·∫£n Gi·ªëc, th·ªùi ƒëi·ªÉm ƒë·∫πp nh·∫•t ƒë·ªÉ gh√© thƒÉm, hay c√°c th√¥ng tin kh√°c kh√¥ng?\n",
      "\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "‚úÖ Agent remembered the entire conversation and knows which place is 'ƒë·ªãa ƒëi·ªÉm ƒë·∫ßu ti√™n'!\n"
     ]
    }
   ],
   "source": [
    "# Resume the first conversation\n",
    "print(f\"üîë Resuming Original Thread: {conversation_thread_id}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Continue where we left off\n",
    "response_continue = chat_with_agent(\n",
    "    \"C·∫£m ∆°n! Cho t√¥i bi·∫øt th√™m v·ªÅ ƒë·ªãa ƒëi·ªÉm ƒë·∫ßu ti√™n nh√©\",\n",
    "    thread_id=conversation_thread_id  # Original thread = full memory!\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Agent remembered the entire conversation and knows which place is 'ƒë·ªãa ƒëi·ªÉm ƒë·∫ßu ti√™n'!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1e06cc",
   "metadata": {},
   "source": [
    "## Summary: Memory with Checkpointer\n",
    "\n",
    "### ‚úÖ What We Accomplished:\n",
    "\n",
    "1. **PostgreSQL Integration**: Connected agent to database for persistent storage\n",
    "2. **Conversation Memory**: Agent remembers chat history within same thread\n",
    "3. **Thread Isolation**: Different threads = separate conversations\n",
    "4. **Persistence**: Conversations survive restarts (stored in DB)\n",
    "5. **Tool Integration**: Memory works seamlessly with retrieval tools\n",
    "\n",
    "### üîë Key Concepts:\n",
    "\n",
    "| Concept | Explanation |\n",
    "|---------|-------------|\n",
    "| **thread_id** | Unique ID for each conversation. Same ID = same memory |\n",
    "| **checkpointer** | Component that saves/loads conversation state |\n",
    "| **checkpoint** | Snapshot of conversation at a point in time |\n",
    "| **PostgresSaver** | LangGraph's PostgreSQL storage backend |\n",
    "\n",
    "### üìä Database Schema:\n",
    "\n",
    "```\n",
    "checkpoints table:\n",
    "- thread_id: Conversation identifier\n",
    "- checkpoint_id: Specific state snapshot\n",
    "- parent_id: Previous checkpoint (for history)\n",
    "- checkpoint: Serialized state data\n",
    "- metadata: Additional info\n",
    "- created_at: Timestamp\n",
    "```\n",
    "\n",
    "### üöÄ Benefits:\n",
    "\n",
    "1. **Natural Conversations**: Users can reference previous messages\n",
    "2. **Context Awareness**: Agent knows what was discussed\n",
    "3. **Scalability**: Each user gets their own thread_id\n",
    "4. **Debugging**: Can inspect saved states in database\n",
    "5. **Resume Anytime**: Conversations persist across sessions\n",
    "\n",
    "### üí° Usage Pattern:\n",
    "\n",
    "```python\n",
    "# Same user, same session ‚Üí use same thread_id\n",
    "user_thread = f\"user_{user_id}\"\n",
    "\n",
    "# First message\n",
    "chat_with_agent(\"T√¨m b√£i bi·ªÉn\", thread_id=user_thread)\n",
    "\n",
    "# Follow-up (agent remembers!)\n",
    "chat_with_agent(\"C√°i n√†o ƒë·∫πp nh·∫•t?\", thread_id=user_thread)\n",
    "```\n",
    "\n",
    "### üîß Next Steps:\n",
    "\n",
    "1. Integrate this into your Chainlit app (`cl_app.py`)\n",
    "2. Use `cl.user_session.get(\"id\")` as thread_id\n",
    "3. Add cleanup for old checkpoints\n",
    "4. Monitor database size over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40fa53b",
   "metadata": {},
   "source": [
    "## 15. Using Remote Embedding API with gradio_client\n",
    "\n",
    "Call the embedding API hosted on HuggingFace Spaces using the Python client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7941bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://hienlong-tourism-embedding-api.hf.space/ ‚úî\n",
      "Client.predict() Usage Info\n",
      "---------------------------\n",
      "Named API endpoints: 3\n",
      "\n",
      " - predict(text, api_name=\"/show_embedding\") -> embedding_vector_first_10_dims\n",
      "    Parameters:\n",
      "     - [Textbox] text: str (required)  \n",
      "    Returns:\n",
      "     - [Textbox] embedding_vector_first_10_dims: str \n",
      "\n",
      " - predict(texts, api_name=\"/show_batch_embeddings\") -> results\n",
      "    Parameters:\n",
      "     - [Textbox] texts: str (required)  \n",
      "    Returns:\n",
      "     - [Textbox] results: str \n",
      "\n",
      " - predict(query, api_name=\"/similarity_search\") -> results\n",
      "    Parameters:\n",
      "     - [Textbox] query: str (required)  \n",
      "    Returns:\n",
      "     - [Textbox] results: str \n",
      "\n",
      "Client.predict() Usage Info\n",
      "---------------------------\n",
      "Named API endpoints: 3\n",
      "\n",
      " - predict(text, api_name=\"/show_embedding\") -> embedding_vector_first_10_dims\n",
      "    Parameters:\n",
      "     - [Textbox] text: str (required)  \n",
      "    Returns:\n",
      "     - [Textbox] embedding_vector_first_10_dims: str \n",
      "\n",
      " - predict(texts, api_name=\"/show_batch_embeddings\") -> results\n",
      "    Parameters:\n",
      "     - [Textbox] texts: str (required)  \n",
      "    Returns:\n",
      "     - [Textbox] results: str \n",
      "\n",
      " - predict(query, api_name=\"/similarity_search\") -> results\n",
      "    Parameters:\n",
      "     - [Textbox] query: str (required)  \n",
      "    Returns:\n",
      "     - [Textbox] results: str \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gradio_client import Client\n",
    "\n",
    "HF_SPACE_URL = \"https://hienlong-tourism-embedding-api.hf.space\"\n",
    "\n",
    "client = Client(HF_SPACE_URL)\n",
    "client.view_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e9d7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hienlong/projects/Tourism-Chatbot/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîó CONNECTING TO REMOTE EMBEDDING API\n",
      "======================================================================\n",
      "Space URL: https://hienlong-tourism-embedding-api.hf.space\n",
      "\n",
      "üì° Initializing gradio_client...\n",
      "Loaded as API: https://hienlong-tourism-embedding-api.hf.space/ ‚úî\n",
      "‚úÖ Client initialized successfully\n",
      "\n",
      "üìù Test 1: Embedding single text...\n",
      "   Input: 'Th√°c n∆∞·ªõc ƒë·∫πp ·ªü Vi·ªát Nam'\n",
      "‚úÖ Client initialized successfully\n",
      "\n",
      "üìù Test 1: Embedding single text...\n",
      "   Input: 'Th√°c n∆∞·ªõc ƒë·∫πp ·ªü Vi·ªát Nam'\n",
      "   ‚úÖ Success!\n",
      "   Embedding dimension: 22631\n",
      "   First 5 values: [0.01\n",
      "\n",
      "üìö Test 2: Embedding multiple documents...\n",
      "   Input: 3 documents\n",
      "   ‚úÖ Success!\n",
      "   Embedding dimension: 22631\n",
      "   First 5 values: [0.01\n",
      "\n",
      "üìö Test 2: Embedding multiple documents...\n",
      "   Input: 3 documents\n",
      "   ‚úÖ Success!\n",
      "   Generated 67931 embeddings\n",
      "   Each embedding dimension: 1\n",
      "\n",
      "üîç Test 3: Similarity search demo...\n",
      "   Query: 'beaches near Danang'\n",
      "   ‚úÖ Success!\n",
      "   Generated 67931 embeddings\n",
      "   Each embedding dimension: 1\n",
      "\n",
      "üîç Test 3: Similarity search demo...\n",
      "   Query: 'beaches near Danang'\n",
      "   ‚úÖ Success!\n",
      "   Result: Query embedded successfully. Vector dimension: 1024\n",
      "Use this embedding to search your ChromaDB insta...\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ALL TESTS PASSED - API IS WORKING!\n",
      "======================================================================\n",
      "   ‚úÖ Success!\n",
      "   Result: Query embedded successfully. Vector dimension: 1024\n",
      "Use this embedding to search your ChromaDB insta...\n",
      "\n",
      "======================================================================\n",
      "‚úÖ ALL TESTS PASSED - API IS WORKING!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from gradio_client import Client\n",
    "\n",
    "# Configure your HF Space URL\n",
    "HF_SPACE_URL = \"https://hienlong-tourism-embedding-api.hf.space\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîó CONNECTING TO REMOTE EMBEDDING API\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Space URL: {HF_SPACE_URL}\\n\")\n",
    "\n",
    "try:\n",
    "    # Initialize client\n",
    "    print(\"üì° Initializing gradio_client...\")\n",
    "    client = Client(HF_SPACE_URL)\n",
    "    print(\"‚úÖ Client initialized successfully\\n\")\n",
    "    \n",
    "    # Test 1: Embed single text\n",
    "    print(\"üìù Test 1: Embedding single text...\")\n",
    "    test_query = \"Th√°c n∆∞·ªõc ƒë·∫πp ·ªü Vi·ªát Nam\"\n",
    "    print(f\"   Input: '{test_query}'\")\n",
    "    \n",
    "    embedding = client.predict(\n",
    "        text=test_query,\n",
    "        api_name=\"/embed_text\"\n",
    "    )\n",
    "    \n",
    "    print(f\"   ‚úÖ Success!\")\n",
    "    print(f\"   Embedding dimension: {len(embedding)}\")\n",
    "    print(f\"   First 5 values: {embedding[:5]}\")\n",
    "    \n",
    "    # Test 2: Embed multiple documents\n",
    "    print(\"\\nüìö Test 2: Embedding multiple documents...\")\n",
    "    test_docs = \"Hoi An Ancient Town\\nMekong Delta\\nHalong Bay\"\n",
    "    print(f\"   Input: {len(test_docs.split(chr(10)))} documents\")\n",
    "    \n",
    "    embeddings = client.predict(\n",
    "        texts=test_docs,\n",
    "        api_name=\"/embed_documents\"\n",
    "    )\n",
    "    \n",
    "    print(f\"   ‚úÖ Success!\")\n",
    "    print(f\"   Generated {len(embeddings)} embeddings\")\n",
    "    print(f\"   Each embedding dimension: {len(embeddings[0])}\")\n",
    "    \n",
    "    # Test 3: Similarity search demo\n",
    "    print(\"\\nüîç Test 3: Similarity search demo...\")\n",
    "    search_query = \"beaches near Danang\"\n",
    "    print(f\"   Query: '{search_query}'\")\n",
    "    \n",
    "    result = client.predict(\n",
    "        query=search_query,\n",
    "        num_results=3,\n",
    "        api_name=\"/similarity_search\"\n",
    "    )\n",
    "    \n",
    "    print(f\"   ‚úÖ Success!\")\n",
    "    print(f\"   Result: {result[:100]}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ ALL TESTS PASSED - API IS WORKING!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error connecting to API: {e}\")\n",
    "    print(\"\\nüí° Troubleshooting:\")\n",
    "    print(\"   1. Check if HF Space is deployed and running\")\n",
    "    print(\"   2. Verify the Space URL is correct\")\n",
    "    print(\"   3. Ensure the Space has the embedding API endpoints\")\n",
    "    print(\"   4. Wait a few minutes if Space is still starting up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cd77205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîó INTEGRATION EXAMPLE: Remote Embeddings + ChromaDB\n",
      "======================================================================\n",
      "\n",
      "üèóÔ∏è Creating RemoteEmbeddingWrapper...\n",
      "\n",
      "Loaded as API: https://hienlong-tourism-embedding-api.hf.space/ ‚úî\n",
      "‚úÖ RemoteEmbeddingWrapper initialized: https://hienlong-tourism-embedding-api.hf.space\n",
      "\n",
      "üìù Testing wrapper with sample query...\n",
      "‚úÖ RemoteEmbeddingWrapper initialized: https://hienlong-tourism-embedding-api.hf.space\n",
      "\n",
      "üìù Testing wrapper with sample query...\n",
      "‚úÖ Query embedding generated: dimension 22688\n",
      "\n",
      "üìö Testing wrapper with sample documents...\n",
      "‚úÖ Query embedding generated: dimension 22688\n",
      "\n",
      "üìö Testing wrapper with sample documents...\n",
      "‚úÖ Document embeddings generated: 68087 embeddings\n",
      "\n",
      "======================================================================\n",
      "‚úÖ WRAPPER IS READY TO USE WITH CHROMADB!\n",
      "======================================================================\n",
      "\n",
      "üí° Usage with ChromaDB:\n",
      "\n",
      "    from langchain_chroma import Chroma\n",
      "\n",
      "    # Use remote embeddings with ChromaDB\n",
      "    vector_store = Chroma.from_documents(\n",
      "        documents=documents,\n",
      "        embedding=remote_embeddings,  # Your remote embedding wrapper\n",
      "        persist_directory=\"./chroma_db\"\n",
      "    )\n",
      "\n",
      "    # Now all similarity searches use remote embeddings!\n",
      "    results = vector_store.similarity_search(\n",
      "        \"beautiful beaches\",\n",
      "        k=5\n",
      "    )\n",
      "    \n",
      "‚úÖ Document embeddings generated: 68087 embeddings\n",
      "\n",
      "======================================================================\n",
      "‚úÖ WRAPPER IS READY TO USE WITH CHROMADB!\n",
      "======================================================================\n",
      "\n",
      "üí° Usage with ChromaDB:\n",
      "\n",
      "    from langchain_chroma import Chroma\n",
      "\n",
      "    # Use remote embeddings with ChromaDB\n",
      "    vector_store = Chroma.from_documents(\n",
      "        documents=documents,\n",
      "        embedding=remote_embeddings,  # Your remote embedding wrapper\n",
      "        persist_directory=\"./chroma_db\"\n",
      "    )\n",
      "\n",
      "    # Now all similarity searches use remote embeddings!\n",
      "    results = vector_store.similarity_search(\n",
      "        \"beautiful beaches\",\n",
      "        k=5\n",
      "    )\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Practical Example: Use Remote Embeddings with ChromaDB\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üîó INTEGRATION EXAMPLE: Remote Embeddings + ChromaDB\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "class RemoteEmbeddingWrapper:\n",
    "    \"\"\"Wrapper to make gradio_client compatible with LangChain\"\"\"\n",
    "    \n",
    "    def __init__(self, space_url: str):\n",
    "        \"\"\"Initialize with HF Space URL\"\"\"\n",
    "        from gradio_client import Client\n",
    "        self.client = Client(space_url)\n",
    "        print(f\"‚úÖ RemoteEmbeddingWrapper initialized: {space_url}\")\n",
    "    \n",
    "    def embed_query(self, text: str):\n",
    "        \"\"\"Embed a single query (LangChain compatible)\"\"\"\n",
    "        try:\n",
    "            result = self.client.predict(text=text, api_name=\"/embed_text\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error embedding query: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def embed_documents(self, texts):\n",
    "        \"\"\"Embed multiple documents (LangChain compatible)\"\"\"\n",
    "        try:\n",
    "            # Join texts with newline (API expects newline-separated)\n",
    "            docs_str = \"\\n\".join(texts)\n",
    "            results = self.client.predict(texts=docs_str, api_name=\"/embed_documents\")\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error embedding documents: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "# Create instance\n",
    "print(\"üèóÔ∏è Creating RemoteEmbeddingWrapper...\\n\")\n",
    "try:\n",
    "    remote_embeddings = RemoteEmbeddingWrapper(HF_SPACE_URL)\n",
    "    \n",
    "    # Test it works\n",
    "    print(\"\\nüìù Testing wrapper with sample query...\")\n",
    "    test_embedding = remote_embeddings.embed_query(\"Ph·ªë c·ªï H·ªôi An\")\n",
    "    print(f\"‚úÖ Query embedding generated: dimension {len(test_embedding)}\")\n",
    "    \n",
    "    print(\"\\nüìö Testing wrapper with sample documents...\")\n",
    "    test_docs = [\n",
    "        \"H·ªôi An l√† m·ªôt th√†nh ph·ªë ven bi·ªÉn c≈© thu·ªôc t·ªânh Qu·∫£ng Nam c≈© (nay l√† ph∆∞·ªùng H·ªôi An, th√†nh ph·ªë ƒê√† N·∫µng), Vi·ªát Nam.\",\n",
    "        \"ƒê·ªìng b·∫±ng s√¥ng C·ª≠u Long l√† b·ªô ph·∫≠n c·ªßa ch√¢u th·ªï s√¥ng M√™ K√¥ng c√≥ di·ªán t√≠ch 34.699,81 km¬≤. C√≥ v·ªã tr√≠ n·∫±m li·ªÅn k·ªÅ v√πng ƒê√¥ng Nam B·ªô v·ªÅ ph√≠a ƒê√¥ng B·∫Øc, ph√≠a T√¢y B·∫Øc gi√°p Campuchia, ph√≠a T√¢y Nam l√† v·ªãnh Th√°i Lan, ph√≠a ƒê√¥ng Nam l√† Bi·ªÉn ƒê√¥ng.\",\n",
    "        \"V·ªãnh H·∫° Long l√† m·ªôt v·ªãnh nh·ªè thu·ªôc ph·∫ßn b·ªù t√¢y v·ªãnh B·∫Øc B·ªô t·∫°i khu v·ª±c bi·ªÉn ƒê√¥ng B·∫Øc Vi·ªát Nam, bao g·ªìm v√πng bi·ªÉn ƒë·∫£o c·ªßa th√†nh ph·ªë H·∫° Long thu·ªôc t·ªânh Qu·∫£ng Ninh.\"\n",
    "    ]\n",
    "    test_embeddings = remote_embeddings.embed_documents(test_docs)\n",
    "    print(f\"‚úÖ Document embeddings generated: {len(test_embeddings)} embeddings\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ WRAPPER IS READY TO USE WITH CHROMADB!\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\nüí° Usage with ChromaDB:\")\n",
    "    print(\"\"\"\n",
    "    from langchain_chroma import Chroma\n",
    "    \n",
    "    # Use remote embeddings with ChromaDB\n",
    "    vector_store = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=remote_embeddings,  # Your remote embedding wrapper\n",
    "        persist_directory=\"./chroma_db\"\n",
    "    )\n",
    "    \n",
    "    # Now all similarity searches use remote embeddings!\n",
    "    results = vector_store.similarity_search(\n",
    "        \"beautiful beaches\",\n",
    "        k=5\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
